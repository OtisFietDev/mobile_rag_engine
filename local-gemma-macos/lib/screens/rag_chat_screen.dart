// local-gemma-macos/lib/screens/rag_chat_screen.dart
//
// RAG + Ollama Chat Screen
// Uses mobile_rag_engine for retrieval and ollama_dart for generation

import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';

import 'package:mobile_rag_engine/mobile_rag_engine.dart';
import 'package:ollama_dart/ollama_dart.dart';

/// Message model for chat
class ChatMessage {
  final String content;
  final bool isUser;
  final DateTime timestamp;
  final List<ChunkSearchResult>? retrievedChunks;
  final int? tokensUsed;
  final double? compressionRatio; // 0.0-1.0, lower = more compressed
  final int? originalTokens; // Before compression

  // Timing metrics for debug
  final Duration? ragSearchTime;
  final Duration? llmGenerationTime;
  final Duration? totalTime;

  ChatMessage({
    required this.content,
    required this.isUser,
    DateTime? timestamp,
    this.retrievedChunks,
    this.tokensUsed,
    this.compressionRatio,
    this.originalTokens,
    this.ragSearchTime,
    this.llmGenerationTime,
    this.totalTime,
  }) : timestamp = timestamp ?? DateTime.now();
}

class RagChatScreen extends StatefulWidget {
  final bool mockLlm;
  final String? modelName;

  const RagChatScreen({super.key, this.mockLlm = false, this.modelName});

  @override
  State<RagChatScreen> createState() => _RagChatScreenState();
}

class _RagChatScreenState extends State<RagChatScreen> {
  final TextEditingController _messageController = TextEditingController();
  final ScrollController _scrollController = ScrollController();
  final FocusNode _focusNode = FocusNode();

  final List<ChatMessage> _messages = [];

  SourceRagService? _ragService;
  bool _isInitialized = false;
  bool _isLoading = false;
  bool _isGenerating = false;
  String _status = 'Initializing...';

  // Ollama client and chat history
  final OllamaClient _ollamaClient = OllamaClient();
  final List<Message> _chatHistory = [];

  // Debug info
  bool _showDebugInfo = true;
  int _totalChunks = 0;
  int _totalSources = 0;

  // Compression settings (Phase 1)
  int _compressionLevel = 1; // 0=minimal, 1=balanced, 2=aggressive

  // Similarity threshold for RAG
  final double _minSimilarityThreshold = 0.35;

  @override
  void initState() {
    super.initState();
    _initialize();
  }

  Future<void> _initialize() async {
    setState(() {
      _isLoading = true;
      _status = 'Initializing RAG engine...';
    });

    try {
      final dir = await getApplicationDocumentsDirectory();
      final dbPath = '${dir.path}/local_gemma_rag.db';
      final tokenizerPath = '${dir.path}/tokenizer.json';

      // 1. Copy BGE-m3 tokenizer
      await _copyAsset('assets/bge-m3-tokenizer.json', tokenizerPath);
      await initTokenizer(tokenizerPath: tokenizerPath);

      // 2. Load BGE-m3 ONNX model (int8 quantized, 1024 dim output)
      setState(() => _status = 'Loading BGE-m3 embedding model...');
      final modelBytes = await rootBundle.load('assets/bge-m3-int8.onnx');
      await EmbeddingService.init(modelBytes.buffer.asUint8List());

      // 3. Initialize RAG service
      _ragService = SourceRagService(
        dbPath: dbPath,
        maxChunkChars: 500,
        overlapChars: 50,
      );
      await _ragService!.init();

      // Get stats
      final stats = await _ragService!.getStats();
      _totalSources = stats.sourceCount.toInt();
      _totalChunks = stats.chunkCount.toInt();

      setState(() {
        _isInitialized = true;
        _isLoading = false;
        _status = 'Ready! Sources: $_totalSources, Chunks: $_totalChunks';
      });

      // Add welcome message
      _addSystemMessage(
        'Welcome! I can answer questions based on the documents you add.\n\n'
        'â€¢ Use the ğŸ“ button to add documents\n'
        'â€¢ Ask me questions about the documents\n'
        'â€¢ ${widget.mockLlm ? "(Mock mode - no LLM)" : "Using Ollama: ${widget.modelName ?? 'default'}"}',
      );
    } catch (e) {
      setState(() {
        _isLoading = false;
        _status = 'Error: $e';
      });
    }
  }

  Future<void> _copyAsset(String assetPath, String targetPath) async {
    final file = File(targetPath);
    if (!await file.exists()) {
      final data = await rootBundle.load(assetPath);
      await file.writeAsBytes(data.buffer.asUint8List());
    }
  }

  void _addSystemMessage(String content) {
    setState(() {
      _messages.insert(0, ChatMessage(content: content, isUser: false));
    });
  }

  Future<void> _sendMessage() async {
    final text = _messageController.text.trim();
    if (text.isEmpty || !_isInitialized || _isGenerating) return;

    _messageController.clear();
    _focusNode.unfocus();

    // Add user message
    setState(() {
      _messages.insert(0, ChatMessage(content: text, isUser: true));
      _isGenerating = true;
    });

    try {
      final totalStopwatch = Stopwatch()..start();

      // 1. RAG Search with timing
      final ragStopwatch = Stopwatch()..start();
      // ë²¡í„° ê²€ìƒ‰ + ì¸ì ‘ ì²­í¬ í¬í•¨ + ë‹¨ì¼ ì†ŒìŠ¤ ëª¨ë“œ
      final ragResult = await _ragService!.search(
        text,
        topK: 10,
        tokenBudget: 4000, // ì••ì¶• ì „ ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        strategy: ContextStrategy.relevanceFirst,
        adjacentChunks: 2, // ì•ë’¤ 2ê°œ ì²­í¬ í¬í•¨
        singleSourceMode: true, // ê°€ì¥ ê´€ë ¨ ë†’ì€ ì†ŒìŠ¤ë§Œ ì‚¬ìš©
      );
      ragStopwatch.stop();
      final ragSearchTime = ragStopwatch.elapsed;

      // DEBUG: Log BGE-m3 search results
      debugPrint('ğŸ” BGE-m3 search for: "$text"');
      debugPrint('   Found ${ragResult.chunks.length} chunks');
      for (var i = 0; i < ragResult.chunks.length && i < 5; i++) {
        final c = ragResult.chunks[i];
        final preview = c.content.length > 50
            ? '${c.content.substring(0, 50)}...'
            : c.content;
        debugPrint('   [$i] sim=${c.similarity.toStringAsFixed(3)}: $preview');
      }

      // Filter low similarity chunks
      // We allow similarity of 0.0 because those are "adjacent chunks" (neighbors)
      // added for context, which don't have a computed similarity score.
      final relevantChunks = ragResult.chunks
          .where(
            (c) =>
                c.similarity >= _minSimilarityThreshold || c.similarity == 0.0,
          )
          .toList();

      if (relevantChunks.length < ragResult.chunks.length) {
        debugPrint(
          '   ğŸ§¹ Filtered ${ragResult.chunks.length - relevantChunks.length} low similarity chunks (<$_minSimilarityThreshold)',
        );
      }

      // Use RAG context directly (no compression)
      // Check if we have ANY relevant chunks after filtering
      final bool hasRelevantContext = relevantChunks.isNotEmpty;

      final contextText = ragResult
          .context
          .text; // Still using full context for now, but prompt will handle "no info"
      final estimatedTokens = ragResult.context.estimatedTokens;
      final chunkCount = ragResult.chunks.length;

      debugPrint(
        'ğŸ“Š RAG Context: $estimatedTokens tokens, $chunkCount chunks (Relevant: ${relevantChunks.length})',
      );

      // 3. LLM Generation with timing
      final llmStopwatch = Stopwatch()..start();
      String response;
      if (widget.mockLlm) {
        // Mock mode
        response = _generateMockResponse(text, ragResult, '0');
      } else {
        // Real LLM generation with Ollama - use RAG context directly
        response = await _generateOllamaResponse(
          text,
          hasRelevantContext ? contextText : '',
          ragResult,
          hasRelevantContext,
        );
      }
      llmStopwatch.stop();
      final llmGenerationTime = llmStopwatch.elapsed;

      totalStopwatch.stop();

      // Add AI response with stats
      setState(() {
        _messages.insert(
          0,
          ChatMessage(
            content: response,
            isUser: false,
            retrievedChunks: ragResult.chunks,
            tokensUsed: estimatedTokens,
            ragSearchTime: ragSearchTime,
            llmGenerationTime: llmGenerationTime,
            totalTime: totalStopwatch.elapsed,
          ),
        );
      });
    } catch (e) {
      setState(() {
        _messages.insert(0, ChatMessage(content: 'âŒ Error: $e', isUser: false));
      });
    } finally {
      setState(() => _isGenerating = false);
    }

    _scrollToBottom();
  }

  String _generateMockResponse(
    String query,
    RagSearchResult ragResult,
    String savedPercent,
  ) {
    if (ragResult.chunks.isEmpty) {
      return 'ğŸ“­ No relevant documents found.\n\nPlease add some documents using the menu.';
    }

    final buffer = StringBuffer();
    buffer.writeln('ğŸ“š Found ${ragResult.chunks.length} relevant chunks:');
    buffer.writeln('ğŸ“Š Using ~${ragResult.context.estimatedTokens} tokens');
    buffer.writeln('ğŸ—œï¸ Reduced by $savedPercent%\n');

    for (var i = 0; i < ragResult.chunks.length && i < 3; i++) {
      final chunk = ragResult.chunks[i];
      final preview = chunk.content.length > 100
          ? '${chunk.content.substring(0, 100)}...'
          : chunk.content;
      buffer.writeln('${i + 1}. $preview\n');
    }

    buffer.writeln('---');
    buffer.writeln(
      'ğŸ’¡ This is a mock response. Install an LLM model for real answers.',
    );

    return buffer.toString();
  }

  /// Generate response using Ollama with pre-compressed context text
  Future<String> _generateOllamaResponseWithCompressedText(
    String query,
    String compressedContext,
    RagSearchResult ragResult,
  ) async {
    try {
      // Build messages with compressed context
      final messages = <Message>[];

      // System message with compressed RAG context
      if (compressedContext.isNotEmpty) {
        messages.add(
          Message(
            role: MessageRole.system,
            content: '''ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ê·œì¹™:
1. ì•„ë˜ ë¬¸ë§¥ì˜ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ë§¥ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ì§ˆë¬¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
4. ì¡°í•­ ë²ˆí˜¸(ì œXì¡°)ëŠ” ë¬¸ë§¥ì— ìˆëŠ” ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ì„¸ìš”.

ë¬¸ë§¥:
$compressedContext''',
          ),
        );
      } else {
        messages.add(
          const Message(
            role: MessageRole.system,
            content: 'You are a helpful assistant.',
          ),
        );
      }

      // Add current user message
      messages.add(Message(role: MessageRole.user, content: query));

      // Save to history
      _chatHistory.add(Message(role: MessageRole.user, content: query));

      // Stream response from Ollama
      final responseBuffer = StringBuffer();

      final stream = _ollamaClient.generateChatCompletionStream(
        request: GenerateChatCompletionRequest(
          model: widget.modelName ?? 'gemma3:4b',
          messages: messages,
        ),
      );

      await for (final chunk in stream) {
        responseBuffer.write(chunk.message.content);
      }

      final response = responseBuffer.toString().trim();

      // Save assistant response to history
      _chatHistory.add(Message(role: MessageRole.assistant, content: response));

      if (response.isEmpty) {
        return 'âš ï¸ The model returned an empty response. Please try again.';
      }

      return response;
    } catch (e, stackTrace) {
      debugPrint('ğŸ”´ Ollama Error: $e');
      debugPrint('ğŸ”´ Stack Trace: $stackTrace');

      return 'âš ï¸ Ollama Error: $e\n\n'
          'Make sure Ollama is running (ollama serve) and the model is installed.';
    }
  }

  Future<String> _generateOllamaResponse(
    String query,
    String contextText,
    RagSearchResult ragResult,
    bool hasRelevantContext,
  ) async {
    try {
      // Build messages
      final messages = <Message>[];

      // 1. System Prompt (Generic strictness instructions, NO context here)
      messages.add(
        const Message(
          role: MessageRole.system,
          content: 'ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ë§¥ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.',
        ),
      );

      // 2. Chat History (last 6 messages to keep context window available for RAG)
      // Reduced from 10 to 6 to prioritize RAG context.
      final historyStart = _chatHistory.length > 6
          ? _chatHistory.length - 6
          : 0;
      messages.addAll(_chatHistory.sublist(historyStart));

      // 3. Current User Message (WITH RAG CONTEXT)
      // We inject the context strictly here to force the model to look at it.
      String finalUserContent;

      if (hasRelevantContext && contextText.isNotEmpty) {
        finalUserContent =
            '''
[ë¬¸ë§¥ ë°ì´í„° ì‹œì‘]
$contextText
[ë¬¸ë§¥ ë°ì´í„° ì¢…ë£Œ]

ì§€ì‹œì‚¬í•­:
ìœ„ [ë¬¸ë§¥ ë°ì´í„°]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. 
ë‚´ìš©ì´ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

ì§ˆë¬¸: $query''';
      } else {
        // Fallback for no context
        finalUserContent =
            '''
ì§ˆë¬¸: $query

ì§€ì‹œì‚¬í•­:
ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ê³µì†í•˜ê²Œ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.''';
      }

      messages.add(Message(role: MessageRole.user, content: finalUserContent));

      // Save raw query to history (not the huge context prompt)
      _chatHistory.add(Message(role: MessageRole.user, content: query));

      // Stream response from Ollama
      final responseBuffer = StringBuffer();

      final stream = _ollamaClient.generateChatCompletionStream(
        request: GenerateChatCompletionRequest(
          model: widget.modelName ?? 'gemma3:4b',
          messages: messages,
        ),
      );

      await for (final chunk in stream) {
        responseBuffer.write(chunk.message.content);
      }

      final response = responseBuffer.toString().trim();

      // Save assistant response to history
      _chatHistory.add(Message(role: MessageRole.assistant, content: response));

      if (response.isEmpty) {
        return 'âš ï¸ The model returned an empty response. Please try again.';
      }

      return response;
    } catch (e, stackTrace) {
      debugPrint('ğŸ”´ Ollama Error: $e');
      debugPrint('ğŸ”´ Stack Trace: $stackTrace');

      return 'âš ï¸ Ollama Error: $e\n\n'
          'Make sure Ollama is running (ollama serve) and the model is installed.';
    }
  }

  /// Start a new chat session - clears messages and chat history
  Future<void> _startNewChat() async {
    setState(() {
      _isLoading = true;
      _status = 'Starting new chat...';
    });

    _chatHistory.clear();

    setState(() {
      _messages.clear();
      _isLoading = false;
      _status = 'Ready! Sources: $_totalSources, Chunks: $_totalChunks';
    });

    _addSystemMessage(
      'ğŸ”„ New chat started! Chat history has been cleared.\n\n'
      'â€¢ Ask me questions about your documents',
    );
  }

  /// Parse simple markdown (bold **text**) into TextSpan
  TextSpan _parseMarkdown(String text) {
    final spans = <TextSpan>[];
    final regex = RegExp(r'\*\*(.+?)\*\*');
    int lastEnd = 0;

    for (final match in regex.allMatches(text)) {
      // Add text before the match
      if (match.start > lastEnd) {
        spans.add(TextSpan(text: text.substring(lastEnd, match.start)));
      }
      // Add bold text
      spans.add(
        TextSpan(
          text: match.group(1),
          style: const TextStyle(fontWeight: FontWeight.bold),
        ),
      );
      lastEnd = match.end;
    }

    // Add remaining text
    if (lastEnd < text.length) {
      spans.add(TextSpan(text: text.substring(lastEnd)));
    }

    // If no matches, return plain text
    if (spans.isEmpty) {
      spans.add(TextSpan(text: text));
    }

    return TextSpan(children: spans);
  }

  void _scrollToBottom() {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (_scrollController.hasClients) {
        _scrollController.animateTo(
          0,
          duration: const Duration(milliseconds: 300),
          curve: Curves.easeOut,
        );
      }
    });
  }

  Future<void> _addSampleDocuments() async {
    if (!_isInitialized) return;

    setState(() {
      _isLoading = true;
      _status = 'Adding sample documents...';
    });

    try {
      final samples = [
        '''Flutter is an open source framework by Google for building beautiful, 
natively compiled, multi-platform applications from a single codebase.
Flutter uses the Dart programming language and provides a rich set of 
pre-designed widgets for creating modern user interfaces.''',

        '''RAG (Retrieval-Augmented Generation) is a technique that combines 
information retrieval with text generation. It first retrieves relevant 
documents from a knowledge base, then uses that context to generate 
more accurate and informed responses.''',

        '''Mobile RAG Engine is a Flutter package that provides on-device 
semantic search capabilities. It uses HNSW (Hierarchical Navigable Small World) 
graphs for efficient vector similarity search, and supports automatic 
document chunking for optimal LLM context assembly.''',

        '''Ollama is an open-source tool that allows you to run large language 
models locally on your machine. It supports various models including Llama, 
Gemma, Mistral, and more. Ollama provides a simple API for generating 
text completions and chat responses.''',
      ];

      for (var i = 0; i < samples.length; i++) {
        setState(
          () => _status = 'Adding document ${i + 1}/${samples.length}...',
        );
        await _ragService!.addSourceWithChunking(samples[i]);
      }

      await _ragService!.rebuildIndex();

      final stats = await _ragService!.getStats();
      _totalSources = stats.sourceCount.toInt();
      _totalChunks = stats.chunkCount.toInt();

      setState(() {
        _isLoading = false;
        _status =
            'Added ${samples.length} documents! Total chunks: $_totalChunks';
      });

      _addSystemMessage(
        'âœ… Added ${samples.length} sample documents with $_totalChunks chunks.',
      );
    } catch (e) {
      setState(() {
        _isLoading = false;
        _status = 'Error: $e';
      });
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text('RAG Chat'),
        centerTitle: true,
        actions: [
          IconButton(
            icon: Icon(
              _showDebugInfo ? Icons.bug_report : Icons.bug_report_outlined,
            ),
            tooltip: 'Toggle debug info',
            onPressed: () => setState(() => _showDebugInfo = !_showDebugInfo),
          ),
          PopupMenuButton<String>(
            onSelected: (value) {
              switch (value) {
                case 'add_samples':
                  _addSampleDocuments();
                  break;
                case 'new_chat':
                  _startNewChat();
                  break;
                case 'clear_chat':
                  setState(() => _messages.clear());
                  break;
                case 'compression_0':
                  setState(() => _compressionLevel = 0);
                  break;
                case 'compression_1':
                  setState(() => _compressionLevel = 1);
                  break;
                case 'compression_2':
                  setState(() => _compressionLevel = 2);
                  break;
              }
            },
            itemBuilder: (context) => [
              const PopupMenuItem(
                value: 'add_samples',
                child: ListTile(
                  leading: Icon(Icons.dataset),
                  title: Text('Add Sample Docs'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
              const PopupMenuItem(
                value: 'new_chat',
                child: ListTile(
                  leading: Icon(Icons.refresh),
                  title: Text('New Chat'),
                  subtitle: Text('Clear chat history'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
              const PopupMenuItem(
                value: 'clear_chat',
                child: ListTile(
                  leading: Icon(Icons.clear_all),
                  title: Text('Clear Chat'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
              const PopupMenuDivider(),
              PopupMenuItem(
                enabled: false,
                child: Text(
                  'Compression Level',
                  style: TextStyle(
                    fontWeight: FontWeight.bold,
                    color: Colors.grey[600],
                  ),
                ),
              ),
              PopupMenuItem(
                value: 'compression_0',
                child: ListTile(
                  leading: Radio<int>(
                    value: 0,
                    groupValue: _compressionLevel,
                    onChanged: null,
                  ),
                  title: const Text('Minimal'),
                  subtitle: const Text('Max context'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
              PopupMenuItem(
                value: 'compression_1',
                child: ListTile(
                  leading: Radio<int>(
                    value: 1,
                    groupValue: _compressionLevel,
                    onChanged: null,
                  ),
                  title: const Text('Balanced'),
                  subtitle: const Text('Default'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
              PopupMenuItem(
                value: 'compression_2',
                child: ListTile(
                  leading: Radio<int>(
                    value: 2,
                    groupValue: _compressionLevel,
                    onChanged: null,
                  ),
                  title: const Text('Aggressive'),
                  subtitle: const Text('Less context'),
                  contentPadding: EdgeInsets.zero,
                ),
              ),
            ],
          ),
        ],
      ),
      body: Column(
        children: [
          // Status bar
          if (_showDebugInfo)
            Container(
              padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
              color: Theme.of(context).colorScheme.surfaceContainerHighest,
              child: Row(
                children: [
                  if (_isLoading)
                    const SizedBox(
                      width: 16,
                      height: 16,
                      child: CircularProgressIndicator(strokeWidth: 2),
                    )
                  else
                    Icon(
                      _isInitialized ? Icons.check_circle : Icons.error,
                      size: 16,
                      color: _isInitialized ? Colors.green : Colors.red,
                    ),
                  const SizedBox(width: 8),
                  Expanded(
                    child: Text(
                      _status,
                      style: const TextStyle(fontSize: 12),
                      overflow: TextOverflow.ellipsis,
                    ),
                  ),
                  Text(
                    'ğŸ“„$_totalSources ğŸ“¦$_totalChunks',
                    style: const TextStyle(fontSize: 12),
                  ),
                ],
              ),
            ),

          // Messages
          Expanded(child: _buildMessageList()),

          // Input area
          _buildInputArea(),
        ],
      ),
    );
  }

  Widget _buildMessageList() {
    if (_messages.isEmpty) {
      return Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Icon(Icons.chat_bubble_outline, size: 64, color: Colors.grey[400]),
            const SizedBox(height: 16),
            Text('No messages yet', style: TextStyle(color: Colors.grey[600])),
            const SizedBox(height: 8),
            TextButton.icon(
              onPressed: _addSampleDocuments,
              icon: const Icon(Icons.add),
              label: const Text('Add sample documents to start'),
            ),
          ],
        ),
      );
    }

    return ListView.builder(
      controller: _scrollController,
      padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 16),
      reverse: true,
      itemCount: _messages.length,
      itemBuilder: (context, index) {
        final message = _messages[index];
        return _buildMessageBubble(message);
      },
    );
  }

  Widget _buildMessageBubble(ChatMessage message) {
    final isUser = message.isUser;

    return Padding(
      padding: const EdgeInsets.only(bottom: 12),
      child: Row(
        mainAxisAlignment: isUser
            ? MainAxisAlignment.end
            : MainAxisAlignment.start,
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          if (!isUser) ...[
            CircleAvatar(
              radius: 18,
              backgroundColor: Theme.of(context).colorScheme.primaryContainer,
              child: const Icon(Icons.smart_toy, size: 20),
            ),
            const SizedBox(width: 8),
          ],
          Flexible(
            child: Column(
              crossAxisAlignment: isUser
                  ? CrossAxisAlignment.end
                  : CrossAxisAlignment.start,
              children: [
                Container(
                  padding: const EdgeInsets.symmetric(
                    horizontal: 14,
                    vertical: 10,
                  ),
                  decoration: BoxDecoration(
                    // User: pink bubble, AI: white bubble (matching existing style)
                    color: isUser ? const Color(0xFFFFE6E6) : Colors.white,
                    borderRadius: BorderRadius.circular(16),
                    border: Border.all(
                      color: isUser
                          ? const Color(0xFFFFDADA)
                          : const Color(0xFFE5E5E5),
                    ),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.grey.withValues(alpha: 0.1),
                        blurRadius: 4,
                        offset: const Offset(0, 2),
                      ),
                    ],
                  ),
                  child: SelectableText.rich(
                    _parseMarkdown(message.content),
                    style: const TextStyle(fontSize: 14, color: Colors.black87),
                  ),
                ),
                // Debug info for AI messages
                if (!isUser && _showDebugInfo && message.tokensUsed != null)
                  Padding(
                    padding: const EdgeInsets.only(top: 4),
                    child: Column(
                      crossAxisAlignment: CrossAxisAlignment.start,
                      children: [
                        Text(
                          '~${message.tokensUsed} tokens â€¢ ${message.retrievedChunks?.length ?? 0} chunks',
                          style: TextStyle(
                            fontSize: 11,
                            color: Colors.grey[500],
                          ),
                        ),
                        if (message.ragSearchTime != null)
                          Text(
                            'âš¡ RAG: ${message.ragSearchTime!.inMilliseconds}ms â€¢ '
                            'LLM: ${message.llmGenerationTime?.inMilliseconds ?? 0}ms â€¢ '
                            'Total: ${message.totalTime?.inMilliseconds ?? 0}ms',
                            style: TextStyle(
                              fontSize: 11,
                              color: Colors.blue[400],
                              fontFamily: 'monospace',
                            ),
                          ),
                      ],
                    ),
                  ),
                // Timestamp
                Padding(
                  padding: const EdgeInsets.only(top: 4),
                  child: Text(
                    _formatTime(message.timestamp),
                    style: TextStyle(fontSize: 11, color: Colors.grey[500]),
                  ),
                ),
              ],
            ),
          ),
          if (isUser) const SizedBox(width: 8),
        ],
      ),
    );
  }

  String _formatTime(DateTime timestamp) {
    final hour = timestamp.hour;
    final period = hour < 12 ? 'ì˜¤ì „' : 'ì˜¤í›„';
    final hour12 = hour == 12 ? 12 : hour % 12;
    final minute = timestamp.minute.toString().padLeft(2, '0');
    return '$period $hour12:$minute';
  }

  Widget _buildInputArea() {
    return Container(
      padding: const EdgeInsets.fromLTRB(16, 8, 12, 8),
      decoration: BoxDecoration(
        color: Colors.white,
        boxShadow: [
          BoxShadow(
            color: Colors.grey.withValues(alpha: 0.12),
            spreadRadius: 10,
            blurRadius: 15,
            offset: const Offset(0, -2),
          ),
        ],
        borderRadius: const BorderRadius.only(
          topLeft: Radius.circular(20),
          topRight: Radius.circular(20),
        ),
      ),
      child: SafeArea(
        child: Row(
          children: [
            // Add document button
            IconButton(
              onPressed: _isInitialized ? _showAddDocumentDialog : null,
              icon: Icon(
                Icons.attach_file,
                color: _isInitialized ? Colors.grey[700] : Colors.grey[400],
              ),
            ),
            // Text input
            Expanded(
              child: TextField(
                controller: _messageController,
                focusNode: _focusNode,
                enabled: _isInitialized && !_isGenerating,
                maxLines: 5,
                minLines: 1,
                textInputAction: TextInputAction.send,
                onSubmitted: (_) => _sendMessage(),
                style: const TextStyle(color: Colors.black87, fontSize: 15),
                decoration: InputDecoration(
                  hintText: 'Ask a question...',
                  hintStyle: TextStyle(color: Colors.grey[500]),
                  filled: true,
                  fillColor: Colors.grey[100],
                  border: OutlineInputBorder(
                    borderRadius: BorderRadius.circular(24),
                    borderSide: BorderSide.none,
                  ),
                  contentPadding: const EdgeInsets.symmetric(
                    horizontal: 16,
                    vertical: 10,
                  ),
                ),
              ),
            ),
            const SizedBox(width: 8),
            // Send button
            GestureDetector(
              onTap: _isGenerating ? null : _sendMessage,
              child: Container(
                width: 40,
                height: 40,
                decoration: BoxDecoration(
                  color: _isGenerating
                      ? Colors.grey
                      : Theme.of(context).colorScheme.primary,
                  shape: BoxShape.circle,
                ),
                child: _isGenerating
                    ? const Padding(
                        padding: EdgeInsets.all(10),
                        child: CircularProgressIndicator(
                          strokeWidth: 2,
                          color: Colors.white,
                        ),
                      )
                    : const Icon(
                        Icons.arrow_upward,
                        color: Colors.white,
                        size: 22,
                      ),
              ),
            ),
          ],
        ),
      ),
    );
  }

  void _showAddDocumentDialog() {
    final controller = TextEditingController();

    showModalBottomSheet(
      context: context,
      isScrollControlled: true,
      shape: const RoundedRectangleBorder(
        borderRadius: BorderRadius.vertical(top: Radius.circular(20)),
      ),
      builder: (context) => Padding(
        padding: EdgeInsets.only(
          bottom: MediaQuery.of(context).viewInsets.bottom,
        ),
        child: Container(
          padding: const EdgeInsets.all(20),
          child: Column(
            mainAxisSize: MainAxisSize.min,
            crossAxisAlignment: CrossAxisAlignment.stretch,
            children: [
              Text(
                'Add Document',
                style: Theme.of(context).textTheme.titleLarge,
              ),
              const SizedBox(height: 16),
              TextField(
                controller: controller,
                maxLines: 6,
                decoration: const InputDecoration(
                  hintText: 'Paste or type document content...',
                  border: OutlineInputBorder(),
                ),
              ),
              const SizedBox(height: 16),
              Row(
                mainAxisAlignment: MainAxisAlignment.end,
                children: [
                  TextButton(
                    onPressed: () => Navigator.pop(context),
                    child: const Text('Cancel'),
                  ),
                  const SizedBox(width: 8),
                  FilledButton(
                    onPressed: () async {
                      final text = controller.text.trim();
                      if (text.isEmpty) return;

                      Navigator.pop(context);

                      setState(() {
                        _isLoading = true;
                        _status = 'Adding document...';
                      });

                      try {
                        final result = await _ragService!.addSourceWithChunking(
                          text,
                        );
                        await _ragService!.rebuildIndex();

                        final stats = await _ragService!.getStats();
                        _totalSources = stats.sourceCount.toInt();
                        _totalChunks = stats.chunkCount.toInt();

                        setState(() {
                          _isLoading = false;
                          _status =
                              'Document added! Chunks: ${result.chunkCount}';
                        });

                        _addSystemMessage(
                          'âœ… Document added with ${result.chunkCount} chunks.',
                        );
                      } catch (e) {
                        setState(() {
                          _isLoading = false;
                          _status = 'Error: $e';
                        });
                      }
                    },
                    child: const Text('Add'),
                  ),
                ],
              ),
            ],
          ),
        ),
      ),
    );
  }

  @override
  void dispose() {
    _messageController.dispose();
    _scrollController.dispose();
    _focusNode.dispose();
    EmbeddingService.dispose();
    super.dispose();
  }
}
